<h4 align="center">
    <p>
        <a href="README_zh.md">ç®€ä½“ä¸­æ–‡</a> |
        <b>English</b>
    </p>
</h4>

# SFT Data Synthesis and Reward Scoring System

<p align="center">
    <img src="../assets/sft-pipeline.png" alt=" SFT æ•°æ®åˆæˆæµç¨‹å›¾" style="max-width: 100%;">
</p>

This codebase providing a complete pipeline from tool graph construction, task generation, trajectory collection to quality assessment.

## ğŸ“ Project Structure

```
trajectory_synthesis/
â”œâ”€â”€ scripts/                                # Execution scripts
â”‚   â”œâ”€â”€ 1_run_graph_pipeline.sh             # Graph construction pipeline: Build tool dependency graph â†’ Random walk to extract sub-chains â†’ Chain verification
â”‚   â”œâ”€â”€ 2_run_task_construction_pipeline.sh # Task construction pipeline: Prompt generation â†’ Query generation â†’ Query augmentation â†’ Quality scoring
â”‚   â”œâ”€â”€ 3_run_interaction_pipeline.sh       # Interaction pipeline: LLM interacts with tool environment to generate execution trajectories
â”‚   â””â”€â”€ 4_run_reward.sh                     # Reward pipeline: Multi-dimensional quality assessment and scoring of trajectories
â”‚
â”œâ”€â”€ src/                                    # Source code
â”‚   â”œâ”€â”€ 1_graph_build/                      # Tool graph construction and verification module
â”‚   â”‚   â”œâ”€â”€ build/                          # Graph construction: LLM detects tool dependencies, random walk to extract sub-chains
â”‚   â”‚   â””â”€â”€ verify/                         # Chain verification: Voting verification, back-translation verification and other operators
â”‚   â”œâ”€â”€ 2_task_construction/                # Task (Query) generation and scoring module
â”‚   â”‚   â”œâ”€â”€ gen/                            # Query generation and augmentation
â”‚   â”‚   â”œâ”€â”€ verify/                         # Query quality scoring
â”‚   â”‚   â””â”€â”€ prompts/                        # Prompt templates
â”‚   â”œâ”€â”€ 3_interaction/                      # LLM-environment interaction module
â”‚   â”‚   â””â”€â”€ qwen_agent/                     # Interaction framework based on Qwen-Agent
â”‚   â”œâ”€â”€ 4_reward/                           # Trajectory quality assessment module
â”‚   â””â”€â”€ utils/                              # Common utility functions (API client, logging, etc.)
â”‚
â””â”€â”€ data/                                   # Input data
    â”œâ”€â”€ mcp_servers.jsonl                   # MCP server configuration: Contains tool list, server information (input for graph construction)
    â”œâ”€â”€ tasks.jsonl                         # Task data: Query, target tools, scoring information (input for interaction pipeline)
    â””â”€â”€ trajectories.jsonl                  # Trajectory data: Conversation history, tool call records (input for Reward pipeline)
```

---

## ğŸš€ Script Description and Execution Methods

### ğŸ”„ Complete Workflow

```
mcp_servers.jsonl
       â†“
[1. Graph Construction Pipeline] â†’ Build tool dependency graph, extract valid tool chains
       â†“
[2. Task Construction Pipeline] â†’ Generate and augment Query, quality scoring
       â†“
[3. Interaction Pipeline] â†’ LLM interacts with environment to generate trajectories
       â†“
[4. Reward Pipeline] â†’ Multi-dimensional quality assessment
       â†“
   Final SFT Data
```

### 1. Graph Construction Pipeline (`1_run_graph_pipeline.sh`)

**Function**: Build tool dependency graph, extract tool chains and verify their validity.

**Steps**:
1. **Graph Construction**: Call LLM to detect dependencies between tools
2. **Random Walk**: Extract sub-chains of specified length from the graph
3. **Chain Verification**: Use verification operators to filter invalid tool chains

**Execution**:
```bash
# Please modify the internal parameters according to your own needs.
bash scripts/1_run_graph_pipeline.sh
```

**Main Parameters**:
| Parameter | Description |
|-----------|-------------|
| `INPUT_FILE` | Tool Document file |
| `MODEL_NAME` | Model name |
| `MIN_LENGTH` / `MAX_LENGTH` | Sub-chain length range |
| `OPERATORS` | Verification operators (comma-separated) |

---

### 2. Task Construction Pipeline (`2_run_task_construction_pipeline.sh`)

**Function**: Generate tasks and perform augmentation and quality scoring.

**Steps**:
1. **Prompt Construction**: Build prompts in different modes
2. **Task Generation**: Call LLM to generate initial tasks
3. **Task Augmentation**: Augment tasks with diversity/complexity/user persona
4. **Quality Scoring**: Score the generated tasks

**Execution**:
```bash
# Please modify the internal parameters according to your own needs.
bash scripts/2_run_task_construction_pipeline.sh 
```

**Main Parameters**:
| Parameter | Description |
|-----------|-------------|
| `INPUT_FILE` | Input file (output from graph pipeline) |
| `AUG_MODE` | Augmentation mode (options: diverse/complicate/add_ug/all) |
| `N_SAMPLE` | Number of samples per prompt |
| `PERSONA_DATASET_PATH` | User persona dataset path |

---

### 3. Interaction Pipeline (`3_run_interaction_pipeline.sh`)

**Function**: Enable LLM to interact with the environment and generate complete execution trajectories.

**Execution**:
```bash
# Please modify the internal parameters according to your own needs.
bash scripts/3_run_interaction_pipeline.sh 
```

**Main Parameters**:
| Parameter | Description |
|-----------|-------------|
| `INPUT_FILE` | Task input file |
| `OUTPUT_FILE` | Output trajectory file |
| `MODEL_NAME` | Model name |
| `MAX_WORKERS` | Maximum concurrency |
| `TIMEOUT` | Single interaction timeout (seconds) |

---

### 4. Reward Assessment Pipeline (`4_run_reward.sh`)

**Function**: Perform multi-dimensional quality assessment on generated trajectories.

**Execution**:
```bash
# Please modify the internal parameters according to your own needs.
bash scripts/4_run_reward.sh
```

**Main Parameters**:
| Parameter | Description |
|-----------|-------------|
| `INPUT_FILE` | Input trajectory file (JSON format) |
| `OUTPUT_DIR` | Output directory |
| `MAX_CONCURRENT` | Maximum concurrent requests |

---

## ğŸ“Š Input Data Description

All input data is located in the `data/` directory, in JSONL format (one JSON object per line).

### `mcp_servers.jsonl`

MCP server configuration information, used as input for the **Graph Construction Pipeline**.

**Data Structure**:
```json
{
  "base_info": {
    "group_info": {
      "server_title": "Server Title",
      "server_name": "Server Name",
      "server_description": "Server Description",
      "domain": "Domain"
    },
    "tool_list": [
      {
        "name": "Tool Name",
        "description": "Tool Description",
        "parameters": { ... }
      }
    ]
  },
  "features": { ... }
}
```

### `tasks.jsonl`

Task data, used as input for the **Interaction Pipeline**.

**Data Structure**:
```json
{
  "query_info": {
    "generated_question": "User Question",
    "target_tools": ["tool1", "tool2"],
    "augmented_query_info": { ... },
    "query_score_info": { ... }
  },
  "mcp_info": { ... },
  "graph": { ... }
}
```

### `trajectories.jsonl`

Interaction trajectory data, used as input for the **Reward Pipeline**.

**Data Structure**:
```json
{
  "tools": [...],
  "messages": [
    {"role": "user", "content": "..."},
    {"role": "assistant", "content": "...", "tool_calls": [...]},
    {"role": "tool", "content": "..."}
  ]
}
```

---

